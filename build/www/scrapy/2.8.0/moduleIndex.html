<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
          "DTD/xhtml1-strict.dtd">
<html>
  
  
  <head>
    
    <title>Module Index</title>
    <meta name="generator" content="pydoctor 22.9.1.dev0"> 
        
    </meta>
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1 maximum-scale=1" />
    <link rel="stylesheet" type="text/css" href="bootstrap.min.css" />
    <link rel="stylesheet" type="text/css" href="apidocs.css" />
    <link rel="stylesheet" type="text/css" href="extra.css" />
</head>

  <body>

    <div id="banner">    
    <div>
        <a href="/">Home</a>
        &gt; scrapy-2.8.0 <!-- This is a placeholder -->
        
        <!-- (<a href=""&gt;show all versions</a&gt;) -->
    </div>
</div>

    <nav class="navbar navbar-default mainnavbar">
      
  
  <div class="container-fluid">


    <div class="navbar-header">
      
      <div class="navlinks">
        <span class="navbar-brand">
          scrapy <a href="index.html">API Documentation</a>
        </span>

        <a href="moduleIndex.html">
          Modules
        </a>

        <a href="classIndex.html">
          Classes
        </a>

        <a href="nameIndex.html">
          Names
        </a>

        <div id="search-box-container">
          <div class="input-group">
            <input id="search-box" type="search" name="search-query" placeholder="Search..." aria-label="Search" minlength="2" class="form-control" autocomplete="off" />
            
            <span class="input-group-btn">
              <a style="display: none;" class="btn btn-default" id="search-clear-button" title="Clear" onclick="clearSearch()"><img src="fonts/x-circle.svg" alt="Clear" /></a>
              <a class="btn btn-default" id="search-help-button" title="Help" onclick="toggleSearchHelpText()"><img src="fonts/info.svg" alt="Help" /></a>
            </span>
          </div>
        </div>

      </div>

      <div id="search-results-container" style="display: none;">
        
        <div id="search-buttons">
          <span class="label label-default" id="search-docstrings-button">
          <label class="checkbox-inline">
            <input type="checkbox" id="toggle-search-in-docstrings-checkbox" value="false" onclick="toggleSearchInDocstrings()">
              search in docstrings
            </input>
          </label>
          </span>
          
        </div>
        
        <noscript>
            <h1>Cannot search: JavaScript is not supported/enabled in your browser.</h1>
        </noscript>

        <div class="hint" id="search-help-box">
          <p class="rst-last">
      
            Search bar offers the following options:
            <ul>   
                <li>
                  <strong>Term presence.</strong> The below example searches for documents that 
                    must contain “foo”, might contain “bar” and must not contain “baz”: <code>+foo bar -baz</code>
                </li> 

                <li>
                  <strong>Wildcards.</strong> The below example searches for documents with words beginning with “foo”: <code>foo*</code>
                </li> 

                <li>
                  <strong>Search in specific fields.</strong> The following search matches all objects 
                  in "twisted.mail" that matches “search”: <code>+qname:twisted.mail.* +search</code>

                  <p>
                    Possible fields: 'name', 'qname' (fully qualified name), 'docstring', and 'kind'.
                    Last two fields are only applicable if "search in docstrings" is enabled.
                  </p>
                </li>

                <li>
                  <strong>Fuzzy matches.</strong> The following search matches all documents 
                  that have a word within 1 edit distance of “foo”: <code>foo~1</code>
                </li>
            </ul>

          </p>
        </div>

        <div id="search-status"> </div>

        <div class="warning" id="search-warn-box" style="display: none;">
          <p class="rst-last"><span id="search-warn"></span></p>
        </div>

        <table id="search-results">
          <!-- Filled dynamically by JS -->
        </table>
        
        <div style="margin-top: 8px;">
          <p>Results provided by <a href="https://lunrjs.com">Lunr.js</a></p>
        </div>
      </div>

    </div>


  </div>
</nav>

    <div class="container-fluid">

      <div class="page-header">
        <h1>Module Index</h1>
        <div id="showPrivate">
          <button class="btn btn-link" onclick="togglePrivate()">Toggle Private API</button>
        </div>
      </div>

      <ul id="summaryTree"><li><code><a href="index.html" class="internal-link">scrapy</a></code> - Scrapy - a web crawling and web scraping framework written for Python<ul><li><code><a href="scrapy.cmdline.html" class="internal-link" title="scrapy.cmdline">cmdline</a></code> - <span class="undocumented">Undocumented</span></li><li><code><a href="scrapy.commands.html" class="internal-link" title="scrapy.commands">commands</a></code> - Base class for Scrapy commands<ul><li><code><a href="scrapy.commands.bench.html" class="internal-link" title="scrapy.commands.bench">bench</a></code> - <span class="undocumented">No module docstring; 1/3 class documented</span></li><li><code><a href="scrapy.commands.check.html" class="internal-link" title="scrapy.commands.check">check</a></code> - <span class="undocumented">Undocumented</span></li><li><code><a href="scrapy.commands.crawl.html" class="internal-link" title="scrapy.commands.crawl">crawl</a></code> - <span class="undocumented">Undocumented</span></li><li><code><a href="scrapy.commands.edit.html" class="internal-link" title="scrapy.commands.edit">edit</a></code> - <span class="undocumented">Undocumented</span></li><li><code><a href="scrapy.commands.fetch.html" class="internal-link" title="scrapy.commands.fetch">fetch</a></code> - <span class="undocumented">Undocumented</span></li><li><code><a href="scrapy.commands.genspider.html" class="internal-link" title="scrapy.commands.genspider">genspider</a></code> - <span class="undocumented">No module docstring; 2/2 functions, 0/1 class documented</span></li><li><code><a href="scrapy.commands.list.html" class="internal-link" title="scrapy.commands.list">list</a></code> - <span class="undocumented">Undocumented</span></li><li><code><a href="scrapy.commands.parse.html" class="internal-link" title="scrapy.commands.parse">parse</a></code> - <span class="undocumented">Undocumented</span></li><li><code><a href="scrapy.commands.runspider.html" class="internal-link" title="scrapy.commands.runspider">runspider</a></code> - <span class="undocumented">Undocumented</span></li><li><code><a href="scrapy.commands.settings.html" class="internal-link" title="scrapy.commands.settings">settings</a></code> - <span class="undocumented">Undocumented</span></li><li><code><a href="scrapy.commands.shell.html" class="internal-link" title="scrapy.commands.shell">shell</a></code> - Scrapy Shell</li><li><code><a href="scrapy.commands.startproject.html" class="internal-link" title="scrapy.commands.startproject">startproject</a></code> - <span class="undocumented">Undocumented</span></li><li><code><a href="scrapy.commands.version.html" class="internal-link" title="scrapy.commands.version">version</a></code> - <span class="undocumented">Undocumented</span></li><li><code><a href="scrapy.commands.view.html" class="internal-link" title="scrapy.commands.view">view</a></code> - <span class="undocumented">Undocumented</span></li></ul></li><li><code><a href="scrapy.contracts.html" class="internal-link" title="scrapy.contracts">contracts</a></code> - <span class="undocumented">No package docstring; 0/1 function, 1/2 class, 0/1 module documented</span><ul><li><code><a href="scrapy.contracts.default.html" class="internal-link" title="scrapy.contracts.default">default</a></code> - <span class="undocumented">No module docstring; 4/4 classes documented</span></li></ul></li><li><code><a href="scrapy.core.html" class="internal-link" title="scrapy.core">core</a></code> - Scrapy core library classes and functions.<ul><li><code><a href="scrapy.core.downloader.html" class="internal-link" title="scrapy.core.downloader">downloader</a></code> - <span class="undocumented">No package docstring; 0/1 function, 1/2 class, 1/4 module, 1/1 package documented</span><ul><li><code><a href="scrapy.core.downloader.contextfactory.html" class="internal-link" title="scrapy.core.downloader.contextfactory">contextfactory</a></code> - <span class="undocumented">No module docstring; 0/1 function, 3/3 classes documented</span></li><li><code><a href="scrapy.core.downloader.handlers.html" class="internal-link" title="scrapy.core.downloader.handlers">handlers</a></code> - Download handlers for different schemes<ul><li><code><a href="scrapy.core.downloader.handlers.datauri.html" class="internal-link" title="scrapy.core.downloader.handlers.datauri">datauri</a></code> - <span class="undocumented">Undocumented</span></li><li><code><a href="scrapy.core.downloader.handlers.file.html" class="internal-link" title="scrapy.core.downloader.handlers.file">file</a></code> - <span class="undocumented">Undocumented</span></li><li><code><a href="scrapy.core.downloader.handlers.ftp.html" class="internal-link" title="scrapy.core.downloader.handlers.ftp">ftp</a></code> - An asynchronous FTP file download handler for scrapy which somehow emulates an http response.</li><li><code><a href="scrapy.core.downloader.handlers.http.html" class="internal-link" title="scrapy.core.downloader.handlers.http">http</a></code> - <span class="undocumented">Undocumented</span></li><li><code><a href="scrapy.core.downloader.handlers.http10.html" class="internal-link" title="scrapy.core.downloader.handlers.http10">http10</a></code> - Download handlers for http and https schemes</li><li><code><a href="scrapy.core.downloader.handlers.http11.html" class="internal-link" title="scrapy.core.downloader.handlers.http11">http11</a></code> - Download handlers for http and https schemes</li><li><code><a href="scrapy.core.downloader.handlers.http2.html" class="internal-link" title="scrapy.core.downloader.handlers.http2">http2</a></code> - <span class="undocumented">Undocumented</span></li><li><code><a href="scrapy.core.downloader.handlers.s3.html" class="internal-link" title="scrapy.core.downloader.handlers.s3">s3</a></code> - <span class="undocumented">Undocumented</span></li></ul></li><li><code><a href="scrapy.core.downloader.middleware.html" class="internal-link" title="scrapy.core.downloader.middleware">middleware</a></code> - Downloader Middleware manager</li><li><code><a href="scrapy.core.downloader.tls.html" class="internal-link" title="scrapy.core.downloader.tls">tls</a></code> - <span class="undocumented">No module docstring; 0/5 variable, 0/2 constant, 1/1 class documented</span></li><li><code><a href="scrapy.core.downloader.webclient.html" class="internal-link" title="scrapy.core.downloader.webclient">webclient</a></code> - <span class="undocumented">No module docstring; 1/2 function, 0/2 class documented</span></li></ul></li><li><code><a href="scrapy.core.engine.html" class="internal-link" title="scrapy.core.engine">engine</a></code> - This is the Scrapy engine which controls the Scheduler, Downloader and Spider.</li><li><code><a href="scrapy.core.http2.html" class="internal-link" title="scrapy.core.http2">http2</a></code> - <span class="undocumented">Undocumented</span><ul><li><code><a href="scrapy.core.http2.agent.html" class="internal-link" title="scrapy.core.http2.agent">agent</a></code> - <span class="undocumented">Undocumented</span></li><li><code><a href="scrapy.core.http2.protocol.html" class="internal-link" title="scrapy.core.http2.protocol">protocol</a></code> - <span class="undocumented">Undocumented</span></li><li><code><a href="scrapy.core.http2.stream.html" class="internal-link" title="scrapy.core.http2.stream">stream</a></code> - <span class="undocumented">No module docstring; 0/1 variable, 2/4 classes documented</span></li></ul></li><li><code><a href="scrapy.core.scheduler.html" class="internal-link" title="scrapy.core.scheduler">scheduler</a></code> - <span class="undocumented">No module docstring; 0/1 variable, 0/1 type variable, 3/3 classes documented</span></li><li><code><a href="scrapy.core.scraper.html" class="internal-link" title="scrapy.core.scraper">scraper</a></code> - This module implements the Scraper component which parses responses and extracts information from them</li><li><code><a href="scrapy.core.spidermw.html" class="internal-link" title="scrapy.core.spidermw">spidermw</a></code> - Spider Middleware manager</li></ul></li><li><code><a href="scrapy.crawler.html" class="internal-link" title="scrapy.crawler">crawler</a></code> - <span class="undocumented">No module docstring; 0/1 variable, 2/3 classes documented</span></li><li><code><a href="scrapy.downloadermiddlewares.html" class="internal-link" title="scrapy.downloadermiddlewares">downloadermiddlewares</a></code> - <span class="undocumented">No package docstring; 7/14 modules documented</span><ul><li><code><a href="scrapy.downloadermiddlewares.ajaxcrawl.html" class="internal-link" title="scrapy.downloadermiddlewares.ajaxcrawl">ajaxcrawl</a></code> - <span class="undocumented">No module docstring; 0/2 variable, 1/1 function, 1/1 class documented</span></li><li><code><a href="scrapy.downloadermiddlewares.cookies.html" class="internal-link" title="scrapy.downloadermiddlewares.cookies">cookies</a></code> - <span class="undocumented">No module docstring; 0/2 variable, 0/1 function, 1/1 class documented</span></li><li><code><a href="scrapy.downloadermiddlewares.decompression.html" class="internal-link" title="scrapy.downloadermiddlewares.decompression">decompression</a></code> - This module implements the DecompressionMiddleware which tries to recognise and extract the potentially compressed responses that may arrive.</li><li><code><a href="scrapy.downloadermiddlewares.defaultheaders.html" class="internal-link" title="scrapy.downloadermiddlewares.defaultheaders">defaultheaders</a></code> - DefaultHeaders downloader middleware</li><li><code><a href="scrapy.downloadermiddlewares.downloadtimeout.html" class="internal-link" title="scrapy.downloadermiddlewares.downloadtimeout">downloadtimeout</a></code> - Download timeout middleware</li><li><code><a href="scrapy.downloadermiddlewares.httpauth.html" class="internal-link" title="scrapy.downloadermiddlewares.httpauth">httpauth</a></code> - HTTP basic auth downloader middleware</li><li><code><a href="scrapy.downloadermiddlewares.httpcache.html" class="internal-link" title="scrapy.downloadermiddlewares.httpcache">httpcache</a></code> - <span class="undocumented">Undocumented</span></li><li><code><a href="scrapy.downloadermiddlewares.httpcompression.html" class="internal-link" title="scrapy.downloadermiddlewares.httpcompression">httpcompression</a></code> - <span class="undocumented">No module docstring; 0/1 constant, 1/1 class documented</span></li><li><code><a href="scrapy.downloadermiddlewares.httpproxy.html" class="internal-link" title="scrapy.downloadermiddlewares.httpproxy">httpproxy</a></code> - <span class="undocumented">Undocumented</span></li><li><code><a href="scrapy.downloadermiddlewares.redirect.html" class="internal-link" title="scrapy.downloadermiddlewares.redirect">redirect</a></code> - <span class="undocumented">No module docstring; 0/1 variable, 0/1 function, 1/3 class documented</span></li><li><code><a href="scrapy.downloadermiddlewares.retry.html" class="internal-link" title="scrapy.downloadermiddlewares.retry">retry</a></code> - An extension to retry failed requests that are potentially caused by temporary problems such as a connection timeout or HTTP 500 error.</li><li><code><a href="scrapy.downloadermiddlewares.robotstxt.html" class="internal-link" title="scrapy.downloadermiddlewares.robotstxt">robotstxt</a></code> - This is a middleware to respect robots.txt policies. To activate it you must enable this middleware and enable the ROBOTSTXT_OBEY setting.</li><li><code><a href="scrapy.downloadermiddlewares.stats.html" class="internal-link" title="scrapy.downloadermiddlewares.stats">stats</a></code> - <span class="undocumented">Undocumented</span></li><li><code><a href="scrapy.downloadermiddlewares.useragent.html" class="internal-link" title="scrapy.downloadermiddlewares.useragent">useragent</a></code> - Set User-Agent header per spider or use a default value from settings</li></ul></li><li><code><a href="scrapy.dupefilters.html" class="internal-link" title="scrapy.dupefilters">dupefilters</a></code> - <span class="undocumented">No module docstring; 0/2 type variable, 1/2 class documented</span></li><li><code><a href="scrapy.exceptions.html" class="internal-link" title="scrapy.exceptions">exceptions</a></code> - Scrapy core exceptions</li><li><code><a href="scrapy.exporters.html" class="internal-link" title="scrapy.exporters">exporters</a></code> - Item Exporters are used to export/serialize items into different formats.</li><li><code><a href="scrapy.extension.html" class="internal-link" title="scrapy.extension">extension</a></code> - The Extension Manager</li><li><code><a href="scrapy.extensions.html" class="internal-link" title="scrapy.extensions">extensions</a></code> - <span class="undocumented">No package docstring; 9/13 modules documented</span><ul><li><code><a href="scrapy.extensions.closespider.html" class="internal-link" title="scrapy.extensions.closespider">closespider</a></code> - CloseSpider is an extension that forces spiders to be closed after certain conditions are met.</li><li><code><a href="scrapy.extensions.corestats.html" class="internal-link" title="scrapy.extensions.corestats">corestats</a></code> - Extension for collecting core stats like items scraped and start/finish times</li><li><code><a href="scrapy.extensions.debug.html" class="internal-link" title="scrapy.extensions.debug">debug</a></code> - Extensions for debugging Scrapy</li><li><code><a href="scrapy.extensions.feedexport.html" class="internal-link" title="scrapy.extensions.feedexport">feedexport</a></code> - Feed Exports extension</li><li><code><a href="scrapy.extensions.httpcache.html" class="internal-link" title="scrapy.extensions.httpcache">httpcache</a></code> - <span class="undocumented">No module docstring; 0/1 variable, 1/2 function, 0/4 class documented</span></li><li><code><a href="scrapy.extensions.logstats.html" class="internal-link" title="scrapy.extensions.logstats">logstats</a></code> - <span class="undocumented">No module docstring; 0/1 variable, 1/1 class documented</span></li><li><code><a href="scrapy.extensions.memdebug.html" class="internal-link" title="scrapy.extensions.memdebug">memdebug</a></code> - MemoryDebugger extension</li><li><code><a href="scrapy.extensions.memusage.html" class="internal-link" title="scrapy.extensions.memusage">memusage</a></code> - MemoryUsage extension</li><li><code><a href="scrapy.extensions.postprocessing.html" class="internal-link" title="scrapy.extensions.postprocessing">postprocessing</a></code> - Extension for processing data before they are exported to feeds.</li><li><code><a href="scrapy.extensions.spiderstate.html" class="internal-link" title="scrapy.extensions.spiderstate">spiderstate</a></code> - <span class="undocumented">No module docstring; 1/1 class documented</span></li><li><code><a href="scrapy.extensions.statsmailer.html" class="internal-link" title="scrapy.extensions.statsmailer">statsmailer</a></code> - StatsMailer extension sends an email when a spider finishes scraping.</li><li><code><a href="scrapy.extensions.telnet.html" class="internal-link" title="scrapy.extensions.telnet">telnet</a></code> - Scrapy Telnet Console extension</li><li><code><a href="scrapy.extensions.throttle.html" class="internal-link" title="scrapy.extensions.throttle">throttle</a></code> - <span class="undocumented">Undocumented</span></li></ul></li><li><code><a href="scrapy.http.html" class="internal-link" title="scrapy.http">http</a></code> - Module containing all HTTP related classes<ul><li><code><a href="scrapy.http.common.html" class="internal-link" title="scrapy.http.common">common</a></code> - <span class="undocumented">Undocumented</span></li><li><code><a href="scrapy.http.cookies.html" class="internal-link" title="scrapy.http.cookies">cookies</a></code> - <span class="undocumented">No module docstring; 0/1 constant, 1/1 function, 1/4 class documented</span></li><li><code><a href="scrapy.http.headers.html" class="internal-link" title="scrapy.http.headers">headers</a></code> - <span class="undocumented">No module docstring; 1/1 class documented</span></li><li><code><a href="scrapy.http.request.html" class="internal-link" title="scrapy.http.request">request</a></code> - This module implements the Request class which is used to represent HTTP requests in Scrapy.<ul><li><code><a href="scrapy.http.request.form.html" class="internal-link" title="scrapy.http.request.form">form</a></code> - This module implements the FormRequest class which is a more convenient class (than Request) to generate Requests based on form data.</li><li><code><a href="scrapy.http.request.json_request.html" class="internal-link" title="scrapy.http.request.json_request">json_request</a></code> - This module implements the JsonRequest class which is a more convenient class (than Request) to generate JSON Requests.</li><li><code><a href="scrapy.http.request.rpc.html" class="internal-link" title="scrapy.http.request.rpc">rpc</a></code> - This module implements the XmlRpcRequest class which is a more convenient class (that Request) to generate xml-rpc requests.</li></ul></li><li><code><a href="scrapy.http.response.html" class="internal-link" title="scrapy.http.response">response</a></code> - This module implements the Response class which is used to represent HTTP responses in Scrapy.<ul><li><code><a href="scrapy.http.response.html.html" class="internal-link" title="scrapy.http.response.html">html</a></code> - This module implements the HtmlResponse class which adds encoding discovering through HTML encoding declarations to the TextResponse class.</li><li><code><a href="scrapy.http.response.text.html" class="internal-link" title="scrapy.http.response.text">text</a></code> - This module implements the TextResponse class which adds encoding handling and discovering (through HTTP headers) to base Response class.</li><li><code><a href="scrapy.http.response.xml.html" class="internal-link" title="scrapy.http.response.xml">xml</a></code> - This module implements the XmlResponse class which adds encoding discovering through XML encoding declarations to the TextResponse class.</li></ul></li></ul></li><li><code><a href="scrapy.interfaces.html" class="internal-link" title="scrapy.interfaces">interfaces</a></code> - <span class="undocumented">Undocumented</span></li><li><code><a href="scrapy.item.html" class="internal-link" title="scrapy.item">item</a></code> - Scrapy Item</li><li><code><a href="scrapy.link.html" class="internal-link" title="scrapy.link">link</a></code> - This module defines the Link object used in Link extractors.</li><li><code><a href="scrapy.linkextractors.html" class="internal-link" title="scrapy.linkextractors">linkextractors</a></code> - scrapy.linkextractors<ul><li><code><a href="scrapy.linkextractors.lxmlhtml.html" class="internal-link" title="scrapy.linkextractors.lxmlhtml">lxmlhtml</a></code> - Link extractor based on lxml.html</li></ul></li><li><code><a href="scrapy.loader.html" class="internal-link" title="scrapy.loader">loader</a></code> - Item Loader<ul><li><code><a href="scrapy.loader.common.html" class="internal-link" title="scrapy.loader.common">common</a></code> - Common functions used in Item Loaders code</li><li><code><a href="scrapy.loader.processors.html" class="internal-link" title="scrapy.loader.processors">processors</a></code> - This module provides some commonly used processors for Item Loaders.</li></ul></li><li><code><a href="scrapy.logformatter.html" class="internal-link" title="scrapy.logformatter">logformatter</a></code> - <span class="undocumented">No module docstring; 0/7 constant, 1/1 class documented</span></li><li><code><a href="scrapy.mail.html" class="internal-link" title="scrapy.mail">mail</a></code> - Mail sending helpers</li><li><code><a href="scrapy.middleware.html" class="internal-link" title="scrapy.middleware">middleware</a></code> - <span class="undocumented">No module docstring; 0/1 variable, 1/1 class documented</span></li><li><code><a href="scrapy.pipelines.html" class="internal-link" title="scrapy.pipelines">pipelines</a></code> - Item pipeline<ul><li><code><a href="scrapy.pipelines.files.html" class="internal-link" title="scrapy.pipelines.files">files</a></code> - Files Pipeline</li><li><code><a href="scrapy.pipelines.images.html" class="internal-link" title="scrapy.pipelines.images">images</a></code> - Images Pipeline</li><li><code><a href="scrapy.pipelines.media.html" class="internal-link" title="scrapy.pipelines.media">media</a></code> - <span class="undocumented">Undocumented</span></li></ul></li><li><code><a href="scrapy.pqueues.html" class="internal-link" title="scrapy.pqueues">pqueues</a></code> - <span class="undocumented">No module docstring; 0/1 variable, 1/1 function, 2/3 classes documented</span></li><li><code><a href="scrapy.resolver.html" class="internal-link" title="scrapy.resolver">resolver</a></code> - <span class="undocumented">No module docstring; 0/1 variable, 2/4 classes documented</span></li><li><code><a href="scrapy.responsetypes.html" class="internal-link" title="scrapy.responsetypes">responsetypes</a></code> - This module implements a class which returns the appropriate Response class based on different criteria.</li><li><code><a href="scrapy.robotstxt.html" class="internal-link" title="scrapy.robotstxt">robotstxt</a></code> - <span class="undocumented">Undocumented</span></li><li><code><a href="scrapy.selector.html" class="internal-link" title="scrapy.selector">selector</a></code> - Selectors<ul><li><code><a href="scrapy.selector.unified.html" class="internal-link" title="scrapy.selector.unified">unified</a></code> - XPath selectors based on lxml</li></ul></li><li><code><a href="scrapy.settings.html" class="internal-link" title="scrapy.settings">settings</a></code> - <span class="undocumented">No package docstring; 0/1 constant, 3/3 functions, 3/3 classes, 1/1 module documented</span><ul><li><code><a href="scrapy.settings.default_settings.html" class="internal-link" title="scrapy.settings.default_settings">default_settings</a></code> - This module contains the default values for all settings used by Scrapy.</li></ul></li><li><code><a href="scrapy.shell.html" class="internal-link" title="scrapy.shell">shell</a></code> - Scrapy Shell</li><li><code><a href="scrapy.signalmanager.html" class="internal-link" title="scrapy.signalmanager">signalmanager</a></code> - <span class="undocumented">Undocumented</span></li><li><code><a href="scrapy.signals.html" class="internal-link" title="scrapy.signals">signals</a></code> - Scrapy signals</li><li><code><a href="scrapy.spiderloader.html" class="internal-link" title="scrapy.spiderloader">spiderloader</a></code> - <span class="undocumented">No module docstring; 1/1 class documented</span></li><li><code><a href="scrapy.spidermiddlewares.html" class="internal-link" title="scrapy.spidermiddlewares">spidermiddlewares</a></code> - <span class="undocumented">No package docstring; 5/5 modules documented</span><ul><li><code><a href="scrapy.spidermiddlewares.depth.html" class="internal-link" title="scrapy.spidermiddlewares.depth">depth</a></code> - Depth Spider Middleware</li><li><code><a href="scrapy.spidermiddlewares.httperror.html" class="internal-link" title="scrapy.spidermiddlewares.httperror">httperror</a></code> - HttpError Spider Middleware</li><li><code><a href="scrapy.spidermiddlewares.offsite.html" class="internal-link" title="scrapy.spidermiddlewares.offsite">offsite</a></code> - Offsite Spider Middleware</li><li><code><a href="scrapy.spidermiddlewares.referer.html" class="internal-link" title="scrapy.spidermiddlewares.referer">referer</a></code> - RefererMiddleware: populates Request referer field, based on the Response which originated it.</li><li><code><a href="scrapy.spidermiddlewares.urllength.html" class="internal-link" title="scrapy.spidermiddlewares.urllength">urllength</a></code> - Url Length Spider Middleware</li></ul></li><li><code><a href="scrapy.spiders.html" class="internal-link" title="scrapy.spiders">spiders</a></code> - Base class for Scrapy spiders<ul><li><code><a href="scrapy.spiders.crawl.html" class="internal-link" title="scrapy.spiders.crawl">crawl</a></code> - This modules implements the CrawlSpider which is the recommended spider to use for scraping typical web sites that requires crawling pages.</li><li><code><a href="scrapy.spiders.feed.html" class="internal-link" title="scrapy.spiders.feed">feed</a></code> - This module implements the XMLFeedSpider which is the recommended spider to use for scraping from an XML feed.</li><li><code><a href="scrapy.spiders.init.html" class="internal-link" title="scrapy.spiders.init">init</a></code> - <span class="undocumented">No module docstring; 1/1 class documented</span></li><li><code><a href="scrapy.spiders.sitemap.html" class="internal-link" title="scrapy.spiders.sitemap">sitemap</a></code> - <span class="undocumented">Undocumented</span></li></ul></li><li><code><a href="scrapy.squeues.html" class="internal-link" title="scrapy.squeues">squeues</a></code> - Scheduler queues</li><li><code><a href="scrapy.statscollectors.html" class="internal-link" title="scrapy.statscollectors">statscollectors</a></code> - Scrapy extension for collecting scraping stats</li><li><code><a href="scrapy.utils.html" class="internal-link" title="scrapy.utils">utils</a></code> - <span class="undocumented">No package docstring; 17/38 modules documented</span><ul><li><code><a href="scrapy.utils.asyncgen.html" class="internal-link" title="scrapy.utils.asyncgen">asyncgen</a></code> - <span class="undocumented">No module docstring; 1/2 function documented</span></li><li><code><a href="scrapy.utils.benchserver.html" class="internal-link" title="scrapy.utils.benchserver">benchserver</a></code> - <span class="undocumented">Undocumented</span></li><li><code><a href="scrapy.utils.boto.html" class="internal-link" title="scrapy.utils.boto">boto</a></code> - Boto/botocore helpers</li><li><code><a href="scrapy.utils.conf.html" class="internal-link" title="scrapy.utils.conf">conf</a></code> - <span class="undocumented">No module docstring; 6/8 functions documented</span></li><li><code><a href="scrapy.utils.console.html" class="internal-link" title="scrapy.utils.console">console</a></code> - <span class="undocumented">No module docstring; 0/1 constant, 6/6 functions documented</span></li><li><code><a href="scrapy.utils.curl.html" class="internal-link" title="scrapy.utils.curl">curl</a></code> - <span class="undocumented">No module docstring; 0/2 variable, 1/2 function, 0/1 class documented</span></li><li><code><a href="scrapy.utils.datatypes.html" class="internal-link" title="scrapy.utils.datatypes">datatypes</a></code> - This module contains data types used by Scrapy which are not included in the Python Standard Library.</li><li><code><a href="scrapy.utils.decorators.html" class="internal-link" title="scrapy.utils.decorators">decorators</a></code> - <span class="undocumented">No module docstring; 3/3 functions documented</span></li><li><code><a href="scrapy.utils.defer.html" class="internal-link" title="scrapy.utils.defer">defer</a></code> - Helper functions for dealing with Twisted deferreds</li><li><code><a href="scrapy.utils.deprecate.html" class="internal-link" title="scrapy.utils.deprecate">deprecate</a></code> - Some helpers for deprecation messages</li><li><code><a href="scrapy.utils.display.html" class="internal-link" title="scrapy.utils.display">display</a></code> - pprint and pformat wrappers with colorization support</li><li><code><a href="scrapy.utils.engine.html" class="internal-link" title="scrapy.utils.engine">engine</a></code> - Some debugging functions for working with the Scrapy engine</li><li><code><a href="scrapy.utils.ftp.html" class="internal-link" title="scrapy.utils.ftp">ftp</a></code> - <span class="undocumented">No module docstring; 2/2 functions documented</span></li><li><code><a href="scrapy.utils.gz.html" class="internal-link" title="scrapy.utils.gz">gz</a></code> - <span class="undocumented">No module docstring; 1/2 function documented</span></li><li><code><a href="scrapy.utils.httpobj.html" class="internal-link" title="scrapy.utils.httpobj">httpobj</a></code> - Helper functions for scrapy.http objects (Request, Response)</li><li><code><a href="scrapy.utils.iterators.html" class="internal-link" title="scrapy.utils.iterators">iterators</a></code> - <span class="undocumented">No module docstring; 0/1 variable, 2/4 functions, 0/1 class documented</span></li><li><code><a href="scrapy.utils.job.html" class="internal-link" title="scrapy.utils.job">job</a></code> - <span class="undocumented">Undocumented</span></li><li><code><a href="scrapy.utils.log.html" class="internal-link" title="scrapy.utils.log">log</a></code> - <span class="undocumented">No module docstring; 0/2 variable, 0/1 constant, 4/8 functions, 3/3 classes documented</span></li><li><code><a href="scrapy.utils.misc.html" class="internal-link" title="scrapy.utils.misc">misc</a></code> - Helper functions which don't fit anywhere else</li><li><code><a href="scrapy.utils.ossignal.html" class="internal-link" title="scrapy.utils.ossignal">ossignal</a></code> - <span class="undocumented">No module docstring; 0/2 variable, 1/1 function documented</span></li><li><code><a href="scrapy.utils.project.html" class="internal-link" title="scrapy.utils.project">project</a></code> - <span class="undocumented">No module docstring; 0/2 constant, 2/4 functions documented</span></li><li><code><a href="scrapy.utils.python.html" class="internal-link" title="scrapy.utils.python">python</a></code> - This module contains essential stuff that should've come with Python itself ;)</li><li><code><a href="scrapy.utils.reactor.html" class="internal-link" title="scrapy.utils.reactor">reactor</a></code> - <span class="undocumented">No module docstring; 4/8 functions, 1/1 class documented</span></li><li><code><a href="scrapy.utils.reqser.html" class="internal-link" title="scrapy.utils.reqser">reqser</a></code> - <span class="undocumented">Undocumented</span></li><li><code><a href="scrapy.utils.request.html" class="internal-link" title="scrapy.utils.request">request</a></code> - This module provides some useful functions for working with scrapy.http.Request objects</li><li><code><a href="scrapy.utils.response.html" class="internal-link" title="scrapy.utils.response">response</a></code> - This module provides some useful functions for working with scrapy.http.Response objects</li><li><code><a href="scrapy.utils.serialize.html" class="internal-link" title="scrapy.utils.serialize">serialize</a></code> - <span class="undocumented">Undocumented</span></li><li><code><a href="scrapy.utils.signal.html" class="internal-link" title="scrapy.utils.signal">signal</a></code> - Helper functions for working with signals</li><li><code><a href="scrapy.utils.sitemap.html" class="internal-link" title="scrapy.utils.sitemap">sitemap</a></code> - Module for processing Sitemaps.</li><li><code><a href="scrapy.utils.spider.html" class="internal-link" title="scrapy.utils.spider">spider</a></code> - <span class="undocumented">No module docstring; 0/1 variable, 2/3 functions, 0/1 class documented</span></li><li><code><a href="scrapy.utils.ssl.html" class="internal-link" title="scrapy.utils.ssl">ssl</a></code> - <span class="undocumented">Undocumented</span></li><li><code><a href="scrapy.utils.template.html" class="internal-link" title="scrapy.utils.template">template</a></code> - Helper functions for working with templates</li><li><code><a href="scrapy.utils.test.html" class="internal-link" title="scrapy.utils.test">test</a></code> - This module contains some assorted functions used in tests</li><li><code><a href="scrapy.utils.testproc.html" class="internal-link" title="scrapy.utils.testproc">testproc</a></code> - <span class="undocumented">Undocumented</span></li><li><code><a href="scrapy.utils.testsite.html" class="internal-link" title="scrapy.utils.testsite">testsite</a></code> - <span class="undocumented">Undocumented</span></li><li><code><a href="scrapy.utils.trackref.html" class="internal-link" title="scrapy.utils.trackref">trackref</a></code> - This module provides some functions and classes to record and report references to live object instances.</li><li><code><a href="scrapy.utils.url.html" class="internal-link" title="scrapy.utils.url">url</a></code> - This module contains general purpose URL functions not found in the standard library.</li><li><code><a href="scrapy.utils.versions.html" class="internal-link" title="scrapy.utils.versions">versions</a></code> - <span class="undocumented">Undocumented</span></li></ul></li><li class="private"><code><a href="scrapy.__main__.html" class="internal-link" title="scrapy.__main__">__main__</a></code> - <span class="undocumented">Undocumented</span></li></ul></li></ul>

    </div>

    <footer class="navbar navbar-default">

  
  <div class="container">
    <a href="index.html">API Documentation</a> for scrapy,
  generated by <a href="https://github.com/twisted/pydoctor/">pydoctor</a>
    22.9.1.dev0 at 2023-02-04 22:01:11.
  </div>

  <!-- Search related scripts needs to be loaded at the end of HTML 
    parsing not to introduce overhead and display HTML data asap -->
  <script src="ajax.js" type="text/javascript"></script>
  <script src="searchlib.js" type="text/javascript"></script>
  <script src="search.js" type="text/javascript"></script>

</footer>

    <script src="pydoctor.js" type="text/javascript"></script>

  </body>
</html>